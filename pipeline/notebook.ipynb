{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd41cae-beaa-458c-b269-a72a18dd9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "778b8c0c-baae-4d84-b4c5-0a98f8864f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c95d2b16-1214-48c0-9f92-00a5a5f2d2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/venv/lib/python3.12/site-packages/pandas/__init__.py'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "994f5729-5efb-4f34-9ee8-4600c8b82f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/venv/bin/python'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c456288f-d5b7-4ee0-9b46-4024c3409fa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2509967228.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdf = pd.read_csv(https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz)\u001b[39m\n                                                                                                                   ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71e5c8c9-2872-4956-9d10-81c0f4f94435",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ededfe21-e1a8-4824-b02a-32904fd2f649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37/4176769558.py:1: DtypeWarning: Columns (0: store_and_fwd_flag) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a93f877-2e21-43b6-b3af-b81d1ee9f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow\"\n",
    "FILENAME = \"yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "url = f\"{PREFIX}/{FILENAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91cb50ab-bcda-4fb3-a49c-f9a8fc737f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37/4176769558.py:1: DtypeWarning: Columns (0: store_and_fwd_flag) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bf0b140-a82a-48a4-862d-ba4481804395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0       1.0  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1       1.0  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2       1.0  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3       1.0  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4       2.0  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           2.10         1.0                  N           142            43   \n",
       "1           0.20         1.0                  N           238           151   \n",
       "2          14.70         1.0                  N           132           165   \n",
       "3          10.60         1.0                  N           138           132   \n",
       "4           4.94         1.0                  N            68            33   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0           2.0          8.0    3.0      0.5        0.00           0.0   \n",
       "1           2.0          3.0    0.5      0.5        0.00           0.0   \n",
       "2           1.0         42.0    0.5      0.5        8.65           0.0   \n",
       "3           1.0         29.0    0.5      0.5        6.05           0.0   \n",
       "4           1.0         16.5    0.5      0.5        4.06           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3         11.80                   2.5  \n",
       "1                    0.3          4.30                   0.0  \n",
       "2                    0.3         51.95                   0.0  \n",
       "3                    0.3         36.35                   0.0  \n",
       "4                    0.3         24.36                   2.5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4763cced-f47d-40c7-a62a-d3c6d1396271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369765"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f008db36-1e17-4c23-b525-5b60b4e3e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369760</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-25 08:32:04</td>\n",
       "      <td>2021-01-25 08:49:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.84</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369761</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-25 08:34:00</td>\n",
       "      <td>2021-01-25 09:04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.67</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369762</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-25 08:37:00</td>\n",
       "      <td>2021-01-25 08:53:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.29</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>28.84</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-25 08:28:00</td>\n",
       "      <td>2021-01-25 08:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.24</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>31.79</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369764</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-25 08:38:00</td>\n",
       "      <td>2021-01-25 08:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248</td>\n",
       "      <td>168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.76</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369765 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0             1.0  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1             1.0  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2             1.0  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3             1.0  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4             2.0  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "1369760       NaN  2021-01-25 08:32:04   2021-01-25 08:49:32              NaN   \n",
       "1369761       NaN  2021-01-25 08:34:00   2021-01-25 09:04:00              NaN   \n",
       "1369762       NaN  2021-01-25 08:37:00   2021-01-25 08:53:00              NaN   \n",
       "1369763       NaN  2021-01-25 08:28:00   2021-01-25 08:50:00              NaN   \n",
       "1369764       NaN  2021-01-25 08:38:00   2021-01-25 08:50:00              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 2.10         1.0                  N           142   \n",
       "1                 0.20         1.0                  N           238   \n",
       "2                14.70         1.0                  N           132   \n",
       "3                10.60         1.0                  N           138   \n",
       "4                 4.94         1.0                  N            68   \n",
       "...                ...         ...                ...           ...   \n",
       "1369760           8.80         NaN                NaN           135   \n",
       "1369761           5.86         NaN                NaN            42   \n",
       "1369762           4.45         NaN                NaN            14   \n",
       "1369763          10.04         NaN                NaN           175   \n",
       "1369764           4.93         NaN                NaN           248   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                  43           2.0         8.00   3.00      0.5        0.00   \n",
       "1                 151           2.0         3.00   0.50      0.5        0.00   \n",
       "2                 165           1.0        42.00   0.50      0.5        8.65   \n",
       "3                 132           1.0        29.00   0.50      0.5        6.05   \n",
       "4                  33           1.0        16.50   0.50      0.5        4.06   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "1369760            82           NaN        21.84   2.75      0.5        0.00   \n",
       "1369761           161           NaN        26.67   2.75      0.5        0.00   \n",
       "1369762           106           NaN        25.29   2.75      0.5        0.00   \n",
       "1369763           216           NaN        28.24   2.75      0.5        0.00   \n",
       "1369764           168           NaN        20.76   2.75      0.5        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                 0.0                    0.3         11.80   \n",
       "1                 0.0                    0.3          4.30   \n",
       "2                 0.0                    0.3         51.95   \n",
       "3                 0.0                    0.3         36.35   \n",
       "4                 0.0                    0.3         24.36   \n",
       "...               ...                    ...           ...   \n",
       "1369760           0.0                    0.3         25.39   \n",
       "1369761           0.0                    0.3         30.22   \n",
       "1369762           0.0                    0.3         28.84   \n",
       "1369763           0.0                    0.3         31.79   \n",
       "1369764           0.0                    0.3         24.31   \n",
       "\n",
       "         congestion_surcharge  \n",
       "0                         2.5  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         2.5  \n",
       "...                       ...  \n",
       "1369760                   0.0  \n",
       "1369761                   0.0  \n",
       "1369762                   0.0  \n",
       "1369763                   0.0  \n",
       "1369764                   0.0  \n",
       "\n",
       "[1369765 rows x 18 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "049e5b3a-60bb-42cb-ba7e-ca3bc4279fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                 float64\n",
       "tpep_pickup_datetime         str\n",
       "tpep_dropoff_datetime        str\n",
       "passenger_count          float64\n",
       "trip_distance            float64\n",
       "RatecodeID               float64\n",
       "store_and_fwd_flag           str\n",
       "PULocationID               int64\n",
       "DOLocationID               int64\n",
       "payment_type             float64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "congestion_surcharge     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5830c9c9-bd7d-4ade-bc38-65ec1d09f199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369765, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f5db140-97c2-40d9-bb96-777c4d999d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    \"VendorID\": \"Int64\",\n",
    "    \"passenger_count\": \"Int64\",\n",
    "    \"trip_distance\": \"float64\",\n",
    "    \"RatecodeID\": \"Int64\",\n",
    "    \"store_and_fwd_flag\": \"string\",\n",
    "    \"PULocationID\": \"Int64\",\n",
    "    \"DOLocationID\": \"Int64\",\n",
    "    \"payment_type\": \"Int64\",\n",
    "    \"fare_amount\": \"float64\",\n",
    "    \"extra\": \"float64\",\n",
    "    \"mta_tax\": \"float64\",\n",
    "    \"tip_amount\": \"float64\",\n",
    "    \"tolls_amount\": \"float64\",\n",
    "    \"improvement_surcharge\": \"float64\",\n",
    "    \"total_amount\": \"float64\",\n",
    "    \"congestion_surcharge\": \"float64\"\n",
    "}\n",
    "\n",
    "parse_dates = [\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    url,\n",
    "    dtype=dtype,\n",
    "    parse_dates=parse_dates,\n",
    "    low_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "721237b8-3a37-4c02-a04a-b68e4c301f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2021-01-01 00:30:10   2021-01-01 00:36:12                1   \n",
       "1         1  2021-01-01 00:51:20   2021-01-01 00:52:19                1   \n",
       "2         1  2021-01-01 00:43:30   2021-01-01 01:11:06                1   \n",
       "3         1  2021-01-01 00:15:48   2021-01-01 00:31:01                0   \n",
       "4         2  2021-01-01 00:31:49   2021-01-01 00:48:21                1   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           2.10           1                  N           142            43   \n",
       "1           0.20           1                  N           238           151   \n",
       "2          14.70           1                  N           132           165   \n",
       "3          10.60           1                  N           138           132   \n",
       "4           4.94           1                  N            68            33   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          8.0    3.0      0.5        0.00           0.0   \n",
       "1             2          3.0    0.5      0.5        0.00           0.0   \n",
       "2             1         42.0    0.5      0.5        8.65           0.0   \n",
       "3             1         29.0    0.5      0.5        6.05           0.0   \n",
       "4             1         16.5    0.5      0.5        4.06           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3         11.80                   2.5  \n",
       "1                    0.3          4.30                   0.0  \n",
       "2                    0.3         51.95                   0.0  \n",
       "3                    0.3         36.35                   0.0  \n",
       "4                    0.3         24.36                   2.5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e81ee0b4-3753-40a5-b888-7fa5c8409a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369760</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2021-01-25 08:32:04</td>\n",
       "      <td>2021-01-25 08:49:32</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.80</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>135</td>\n",
       "      <td>82</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21.84</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369761</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2021-01-25 08:34:00</td>\n",
       "      <td>2021-01-25 09:04:00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.86</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>42</td>\n",
       "      <td>161</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>26.67</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369762</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2021-01-25 08:37:00</td>\n",
       "      <td>2021-01-25 08:53:00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.45</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14</td>\n",
       "      <td>106</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>25.29</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>28.84</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369763</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2021-01-25 08:28:00</td>\n",
       "      <td>2021-01-25 08:50:00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10.04</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>175</td>\n",
       "      <td>216</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>28.24</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>31.79</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369764</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2021-01-25 08:38:00</td>\n",
       "      <td>2021-01-25 08:50:00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.93</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>248</td>\n",
       "      <td>168</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20.76</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369765 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2021-01-01 00:30:10   2021-01-01 00:36:12                1   \n",
       "1               1  2021-01-01 00:51:20   2021-01-01 00:52:19                1   \n",
       "2               1  2021-01-01 00:43:30   2021-01-01 01:11:06                1   \n",
       "3               1  2021-01-01 00:15:48   2021-01-01 00:31:01                0   \n",
       "4               2  2021-01-01 00:31:49   2021-01-01 00:48:21                1   \n",
       "...           ...                  ...                   ...              ...   \n",
       "1369760      <NA>  2021-01-25 08:32:04   2021-01-25 08:49:32             <NA>   \n",
       "1369761      <NA>  2021-01-25 08:34:00   2021-01-25 09:04:00             <NA>   \n",
       "1369762      <NA>  2021-01-25 08:37:00   2021-01-25 08:53:00             <NA>   \n",
       "1369763      <NA>  2021-01-25 08:28:00   2021-01-25 08:50:00             <NA>   \n",
       "1369764      <NA>  2021-01-25 08:38:00   2021-01-25 08:50:00             <NA>   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 2.10           1                  N           142   \n",
       "1                 0.20           1                  N           238   \n",
       "2                14.70           1                  N           132   \n",
       "3                10.60           1                  N           138   \n",
       "4                 4.94           1                  N            68   \n",
       "...                ...         ...                ...           ...   \n",
       "1369760           8.80        <NA>               <NA>           135   \n",
       "1369761           5.86        <NA>               <NA>            42   \n",
       "1369762           4.45        <NA>               <NA>            14   \n",
       "1369763          10.04        <NA>               <NA>           175   \n",
       "1369764           4.93        <NA>               <NA>           248   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                  43             2         8.00   3.00      0.5        0.00   \n",
       "1                 151             2         3.00   0.50      0.5        0.00   \n",
       "2                 165             1        42.00   0.50      0.5        8.65   \n",
       "3                 132             1        29.00   0.50      0.5        6.05   \n",
       "4                  33             1        16.50   0.50      0.5        4.06   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "1369760            82          <NA>        21.84   2.75      0.5        0.00   \n",
       "1369761           161          <NA>        26.67   2.75      0.5        0.00   \n",
       "1369762           106          <NA>        25.29   2.75      0.5        0.00   \n",
       "1369763           216          <NA>        28.24   2.75      0.5        0.00   \n",
       "1369764           168          <NA>        20.76   2.75      0.5        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                 0.0                    0.3         11.80   \n",
       "1                 0.0                    0.3          4.30   \n",
       "2                 0.0                    0.3         51.95   \n",
       "3                 0.0                    0.3         36.35   \n",
       "4                 0.0                    0.3         24.36   \n",
       "...               ...                    ...           ...   \n",
       "1369760           0.0                    0.3         25.39   \n",
       "1369761           0.0                    0.3         30.22   \n",
       "1369762           0.0                    0.3         28.84   \n",
       "1369763           0.0                    0.3         31.79   \n",
       "1369764           0.0                    0.3         24.31   \n",
       "\n",
       "         congestion_surcharge  \n",
       "0                         2.5  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         2.5  \n",
       "...                       ...  \n",
       "1369760                   0.0  \n",
       "1369761                   0.0  \n",
       "1369762                   0.0  \n",
       "1369763                   0.0  \n",
       "1369764                   0.0  \n",
       "\n",
       "[1369765 rows x 18 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81f12136-d0fb-4712-9453-fb86604eed15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2021-01-01 00:30:10\n",
       "1         2021-01-01 00:51:20\n",
       "2         2021-01-01 00:43:30\n",
       "3         2021-01-01 00:15:48\n",
       "4         2021-01-01 00:31:49\n",
       "                  ...        \n",
       "1369760   2021-01-25 08:32:04\n",
       "1369761   2021-01-25 08:34:00\n",
       "1369762   2021-01-25 08:37:00\n",
       "1369763   2021-01-25 08:28:00\n",
       "1369764   2021-01-25 08:38:00\n",
       "Name: tpep_pickup_datetime, Length: 1369765, dtype: datetime64[us]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tpep_pickup_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25e31163-f2f0-409f-a5a4-2b3fdb47feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m118 packages\u001b[0m \u001b[2min 0.62ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m114 packages\u001b[0m \u001b[2min 59ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0a5976b-c23e-4216-920d-37e443127d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e889a9e5-e826-4b4a-bfb5-39ab347b1ffd",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:143\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3309\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3288\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3289\u001b[39m \n\u001b[32m   3290\u001b[39m \u001b[33;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3307\u001b[39m \n\u001b[32m   3308\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:447\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    441\u001b[39m \n\u001b[32m    442\u001b[39m \u001b[33;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m \n\u001b[32m    446\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:1264\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:711\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:175\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:388\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:673\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:899\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:895\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    894\u001b[39m \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/create.py:661\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    659\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:630\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs: Any, **cparams: Any) -> DBAPIConnection:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOperationalError\u001b[39m: connection to server at \"localhost\" (::1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myellow_taxi_data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/pandas/io/sql.py:2957\u001b[39m, in \u001b[36mget_schema\u001b[39m\u001b[34m(frame, name, keys, con, dtype, schema)\u001b[39m\n\u001b[32m   2928\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_schema\u001b[39m(\n\u001b[32m   2929\u001b[39m     frame,\n\u001b[32m   2930\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2934\u001b[39m     schema: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2935\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m   2936\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2937\u001b[39m \u001b[33;03m    Get the SQL db table schema for the given frame.\u001b[39;00m\n\u001b[32m   2938\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2955\u001b[39m \u001b[33;03m        Optional specifying the schema to be used in creating the table.\u001b[39;00m\n\u001b[32m   2956\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2957\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m   2958\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql._create_sql_schema(\n\u001b[32m   2959\u001b[39m             frame, name, keys=keys, dtype=dtype, schema=schema\n\u001b[32m   2960\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/pandas/io/sql.py:908\u001b[39m, in \u001b[36mpandasSQL_builder\u001b[39m\u001b[34m(con, schema, need_transaction)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    903\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing URI string without version \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVERSIONS[\u001b[33m'\u001b[39m\u001b[33msqlalchemy\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m or newer \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mof \u001b[39m\u001b[33m'\u001b[39m\u001b[33msqlalchemy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m installed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     )\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy.engine.Connectable)):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSQLDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    910\u001b[39m adbc = import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33madbc_driver_manager.dbapi\u001b[39m\u001b[33m\"\u001b[39m, errors=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m adbc \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, adbc.Connection):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/pandas/io/sql.py:1649\u001b[39m, in \u001b[36mSQLDatabase.__init__\u001b[39m\u001b[34m(self, con, schema, need_transaction)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28mself\u001b[39m.exit_stack.callback(con.dispose)\n\u001b[32m   1648\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, Engine):\n\u001b[32m-> \u001b[39m\u001b[32m1649\u001b[39m     con = \u001b[38;5;28mself\u001b[39m.exit_stack.enter_context(\u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m need_transaction \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m con.in_transaction():\n\u001b[32m   1651\u001b[39m     \u001b[38;5;28mself\u001b[39m.exit_stack.enter_context(con.begin())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3285\u001b[39m, in \u001b[36mEngine.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Connection:\n\u001b[32m   3263\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[32m   3264\u001b[39m \n\u001b[32m   3265\u001b[39m \u001b[33;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3282\u001b[39m \n\u001b[32m   3283\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:145\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    143\u001b[39m         \u001b[38;5;28mself\u001b[39m._dbapi_connection = engine.raw_connection()\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m         \u001b[43mConnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2448\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception_noconnection\u001b[39m\u001b[34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[39m\n\u001b[32m   2446\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2447\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2448\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2449\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2450\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:143\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    145\u001b[39m         Connection._handle_dbapi_exception_noconnection(\n\u001b[32m    146\u001b[39m             err, dialect, engine\n\u001b[32m    147\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3309\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m   3288\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3289\u001b[39m \n\u001b[32m   3290\u001b[39m \u001b[33;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3307\u001b[39m \n\u001b[32m   3308\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:447\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m    440\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    441\u001b[39m \n\u001b[32m    442\u001b[39m \u001b[33;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m \n\u001b[32m    446\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:1264\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1256\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_checkout\u001b[39m(\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1261\u001b[39m     fairy: Optional[_ConnectionFairy] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1262\u001b[39m ) -> _ConnectionFairy:\n\u001b[32m   1263\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m         fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1267\u001b[39m             threadconns.current = weakref.ref(fairy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:711\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    709\u001b[39m     rec = cast(_ConnectionRecord, pool._do_get())\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    714\u001b[39m     dbapi_connection = rec.get_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_connection()\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:175\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inc_overflow():\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    177\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m util.safe_reraise():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:388\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ConnectionPoolEntry:\n\u001b[32m    386\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:673\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    671\u001b[39m \u001b[38;5;28mself\u001b[39m.__pool = pool\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:899\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    902\u001b[39m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[32m    903\u001b[39m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/pool/base.py:895\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    894\u001b[39m     \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m     pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n\u001b[32m    897\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/create.py:661\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    658\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    659\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:630\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs: Any, **cparams: Any) -> DBAPIConnection:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.12/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mOperationalError\u001b[39m: (psycopg2.OperationalError) connection to server at \"localhost\" (::1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555e2fe-c497-4ca1-8f3b-653ce1cb55c9",
   "metadata": {},
   "source": [
    "below approach not production friedly as credentials are hardcoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95a39674-fc6e-4119-ac22-bd4abf007496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine(\"postgresql+psycopg2://root:root@ny_taxi_pg:5432/ny_taxi\")\n",
    "print(pd.io.sql.get_schema(df, name=\"yellow_taxi_data\", con=engine))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c0e03-4165-4df5-b350-23e9bbdc66b0",
   "metadata": {},
   "source": [
    "below option is more production ready as it reads from a .env file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db78c8df-443f-4ddf-b008-33bf47433d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def require_env(name: str) -> str:\n",
    "    value = os.environ.get(name)\n",
    "    if not value:\n",
    "        raise RuntimeError(\n",
    "            f\"Missing env var: {name}. \"\n",
    "            f\"Make sure docker-compose has `env_file: - .env` for the jupyter service.\"\n",
    "        )\n",
    "    return value\n",
    "\n",
    "PG_HOST = os.environ.get(\"POSTGRES_HOST\", \"ny_taxi_pg\")\n",
    "PG_PORT = int(os.environ.get(\"POSTGRES_PORT\", \"5432\"))\n",
    "PG_USER = require_env(\"POSTGRES_USER\")\n",
    "PG_PASS = require_env(\"POSTGRES_PASSWORD\")\n",
    "PG_DB   = require_env(\"POSTGRES_DB\")\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    ")\n",
    "\n",
    "print(pd.io.sql.get_schema(df, name=\"yellow_taxi_data\", con=engine))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d51fb196-b34a-4aa9-bdba-20804d696c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=0).to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "075c137b-dc50-400f-8992-fce2adeae3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=100_000,\n",
    "    dtype={\n",
    "        \"store_and_fwd_flag\": \"string\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6173f18d-6f24-46f8-8893-dad2d4724639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=100_000,\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8de0f60-16e7-4bd0-a816-551e1c945efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "69765\n"
     ]
    }
   ],
   "source": [
    "for df_chunk in df_iter:\n",
    "    print(len(df_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c663cb58-2b62-4e2a-83e8-44fd6914fb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunk.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81cfda6d-f15a-4686-914f-6e3b9556f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/venv/bin/python: No module named uv\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "uv add tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76a6497-a5bf-47db-b137-789b30da061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce6d6a6-202d-4146-84ef-4f2efeaf6f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m df_chunk \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mdf_iter\u001b[49m):\n\u001b[32m      4\u001b[39m     ...\n",
      "\u001b[31mNameError\u001b[39m: name 'df_iter' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for df_chunk in tqdm(df_iter):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4f6fad-2da5-436f-bb0e-d1c1a35feb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=100_000,\n",
    "    dtype={\"store_and_fwd_flag\": \"string\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b46b979-8903-42d9-b8f1-922f90a9966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "304c603e-9670-48eb-b7db-0d7cb447033b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:02,  5.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for df_chunk in tqdm(df_iter):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3449010-a343-466a-90f0-a4970412dd18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:00<00:02,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [00:00<00:01,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 5/14 [00:00<00:01,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6/14 [00:01<00:01,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 7/14 [00:01<00:01,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 9/14 [00:01<00:01,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 11/14 [00:02<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:02<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm  # <- avoids ipywidgets warning\n",
    "\n",
    "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=100_000,\n",
    "    dtype={\"store_and_fwd_flag\": \"string\"},\n",
    ")\n",
    "\n",
    "for df_chunk in tqdm(df_iter, total=14):\n",
    "    print(len(df_chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59349c33-75bc-4d0c-b1ae-b4c7c61027df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for df_chunk in tqdm(df_iter, total=14):\n",
    "    print(len(df_chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f522d1-bb24-4340-8b29-a71725692f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, df_chunk in enumerate(tqdm(df_iter, total=14), start=1):\n",
    "    df_chunk.to_sql(\n",
    "        name=\"yellow_taxi_data\",\n",
    "        con=engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "    )\n",
    "    print(f\"Inserted chunk {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebed4d62-5f1a-4878-8eca-ac807a21130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, df_chunk in enumerate(tqdm(df_iter, total=14), start=1):\n",
    "    print(f\"Chunk {i}, rows={len(df_chunk)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b9fefbf-08da-4de4-a282-8c848630ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting insert loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Starting insert loop...\")\n",
    "\n",
    "for i, df_chunk in enumerate(tqdm(df_iter, total=14), start=1):\n",
    "    print(f\"Chunk {i} loaded, inserting...\")\n",
    "    df_chunk.to_sql(\n",
    "        name=\"yellow_taxi_data\",\n",
    "        con=engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "    )\n",
    "    print(f\"Inserted chunk {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6443f77c-dd7f-4f29-9f4d-ee6d45afdea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterator is exhausted. Recreate df_iter.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    first = next(df_iter)\n",
    "    print(\"Iterator is alive. First chunk rows:\", len(first))\n",
    "except StopIteration:\n",
    "    print(\"Iterator is exhausted. Recreate df_iter.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "000f3529-4920-4aa9-bfdf-613985858e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefetched chunk 1 rows: 100000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrefetched chunk 1 rows:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(first_chunk))\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Create/replace table schema\u001b[39;00m\n\u001b[32m     20\u001b[39m first_chunk.head(\u001b[32m0\u001b[39m).to_sql(\n\u001b[32m     21\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33myellow_taxi_data\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     con=\u001b[43mengine\u001b[49m,\n\u001b[32m     23\u001b[39m     if_exists=\u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m     index=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Insert chunk 1\u001b[39;00m\n\u001b[32m     28\u001b[39m first_chunk.to_sql(\n\u001b[32m     29\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33myellow_taxi_data\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m     con=engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mmulti\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "# Recreate iterator (because it was exhausted)\n",
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=100_000,\n",
    "    dtype={\"store_and_fwd_flag\": \"string\"},\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# Prefetch first chunk (this also proves it's alive)\n",
    "first_chunk = next(df_iter)\n",
    "print(\"Prefetched chunk 1 rows:\", len(first_chunk))\n",
    "\n",
    "# Create/replace table schema\n",
    "first_chunk.head(0).to_sql(\n",
    "    name=\"yellow_taxi_data\",\n",
    "    con=engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "# Insert chunk 1\n",
    "first_chunk.to_sql(\n",
    "    name=\"yellow_taxi_data\",\n",
    "    con=engine,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=\"multi\",\n",
    ")\n",
    "print(\"Inserted chunk 1\")\n",
    "\n",
    "# Insert remaining chunks with progress\n",
    "for i, df_chunk in enumerate(tqdm(df_iter, total=13), start=2):\n",
    "    df_chunk.to_sql(\n",
    "        name=\"yellow_taxi_data\",\n",
    "        con=engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "    )\n",
    "    print(f\"Inserted chunk {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c82669e-c91f-4b31-862c-7f36e780587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine created OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://\"\n",
    "    f\"{os.environ['POSTGRES_USER']}:\"\n",
    "    f\"{os.environ['POSTGRES_PASSWORD']}@\"\n",
    "    f\"{os.environ.get('POSTGRES_HOST', 'ny_taxi_pg')}:\"\n",
    "    f\"{os.environ.get('POSTGRES_PORT', 5432)}/\"\n",
    "    f\"{os.environ['POSTGRES_DB']}\"\n",
    ")\n",
    "\n",
    "print(\"Engine created OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb0763-0717-4b51-b374-fc342b4ff954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefetched chunk 1 rows: 100000\n",
      "Inserted chunk 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=100_000,\n",
    "    dtype={\"store_and_fwd_flag\": \"string\"},\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "first_chunk = next(df_iter)\n",
    "print(\"Prefetched chunk 1 rows:\", len(first_chunk))\n",
    "\n",
    "first_chunk.head(0).to_sql(\n",
    "    name=\"yellow_taxi_data\",\n",
    "    con=engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "first_chunk.to_sql(\n",
    "    name=\"yellow_taxi_data\",\n",
    "    con=engine,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=\"multi\",\n",
    ")\n",
    "print(\"Inserted chunk 1\")\n",
    "\n",
    "for i, df_chunk in enumerate(tqdm(df_iter, total=13), start=2):\n",
    "    df_chunk.to_sql(\n",
    "        name=\"yellow_taxi_data\",\n",
    "        con=engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "    )\n",
    "    print(f\"Inserted chunk {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee3afc8-236e-4a14-a4d2-4845cd148d0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, df_chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(\u001b[43mdf_iter\u001b[49m, total=\u001b[32m13\u001b[39m), start=\u001b[32m2\u001b[39m):\n\u001b[32m      4\u001b[39m     df_chunk.to_sql(\n\u001b[32m      5\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33myellow_taxi_data\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m         con=engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mmulti\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     )\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInserted chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_iter' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, df_chunk in enumerate(tqdm(df_iter, total=13), start=2):\n",
    "    df_chunk.to_sql(\n",
    "        name=\"yellow_taxi_data\",\n",
    "        con=engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "    )\n",
    "    print(f\"Inserted chunk {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64462132-d5e4-4a34-a505-7c442494d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "\n",
    "# recreate engine\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://\"\n",
    "    f\"{os.environ['POSTGRES_USER']}:\"\n",
    "    f\"{os.environ['POSTGRES_PASSWORD']}@\"\n",
    "    f\"{os.environ.get('POSTGRES_HOST','ny_taxi_pg')}:\"\n",
    "    f\"{os.environ.get('POSTGRES_PORT',5432)}/\"\n",
    "    f\"{os.environ['POSTGRES_DB']}\"\n",
    ")\n",
    "\n",
    "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=100_000,\n",
    "    dtype={\"store_and_fwd_flag\": \"string\"},\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# prefetch first chunk\n",
    "first_chunk = next(df_iter)\n",
    "\n",
    "# DROP + recreate table schema\n",
    "first_chunk.head(0).to_sql(\n",
    "    \"yellow_taxi_data\",\n",
    "    con=engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "# insert all chunks\n",
    "first_chunk.to_sql(\n",
    "    \"yellow_taxi_data\",\n",
    "    con=engine,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=\"multi\",\n",
    ")\n",
    "print(\"Inserted chunk 1\")\n",
    "\n",
    "for i, df_chunk in enumerate(tqdm(df_iter, total=13), start=2):\n",
    "    df_chunk.to_sql(\n",
    "        \"yellow_taxi_data\",\n",
    "        con=engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "    )\n",
    "    print(f\"Inserted chunk {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3a44aa-e2e1-45c8-94b1-ff05f436d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n\n",
       "0  0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://\"\n",
    "    f\"{os.environ['POSTGRES_USER']}:{os.environ['POSTGRES_PASSWORD']}\"\n",
    "    f\"@{os.environ.get('POSTGRES_HOST','ny_taxi_pg')}:{os.environ.get('POSTGRES_PORT',5432)}\"\n",
    "    f\"/{os.environ['POSTGRES_DB']}\"\n",
    ")\n",
    "\n",
    "pd.read_sql(\"SELECT COUNT(*) AS n FROM yellow_taxi_data\", con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4323d54-39cb-482e-94fa-8d7c1fc2bda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB connections OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "PG_HOST = os.environ.get(\"POSTGRES_HOST\", \"ny_taxi_pg\")\n",
    "PG_PORT = int(os.environ.get(\"POSTGRES_PORT\", \"5432\"))\n",
    "PG_USER = os.environ[\"POSTGRES_USER\"]\n",
    "PG_PASS = os.environ[\"POSTGRES_PASSWORD\"]\n",
    "PG_DB   = os.environ[\"POSTGRES_DB\"]\n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\")\n",
    "\n",
    "pg_conn = psycopg2.connect(\n",
    "    host=PG_HOST, port=PG_PORT, user=PG_USER, password=PG_PASS, dbname=PG_DB\n",
    ")\n",
    "\n",
    "print(\"DB connections OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665bb9d9-741c-410c-a492-9cd3574d0469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefetched rows: 50000\n",
      "Copied chunk 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied chunk 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:05,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied chunk 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:08,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied chunk 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:12,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied chunk 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:16,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied chunk 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:18,  1.31it/s]\n"
     ]
    },
    {
     "ename": "InvalidTextRepresentation",
     "evalue": "invalid input syntax for type bigint: \"2.0\"\nCONTEXT:  COPY yellow_taxi_data, line 1, column VendorID: \"2.0\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidTextRepresentation\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# COPY the rest with tqdm\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(df_iter), start=\u001b[32m2\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[43mcopy_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpg_conn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     49\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCopied chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mcopy_chunk\u001b[39m\u001b[34m(conn, chunk)\u001b[39m\n\u001b[32m     35\u001b[39m buf.seek(\u001b[32m0\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m conn.cursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy_expert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy_sql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m conn.commit()\n",
      "\u001b[31mInvalidTextRepresentation\u001b[39m: invalid input syntax for type bigint: \"2.0\"\nCONTEXT:  COPY yellow_taxi_data, line 1, column VendorID: \"2.0\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "\n",
    "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "# Stream CSV in chunks (smaller chunks reduce memory spikes)\n",
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=50_000,\n",
    "    dtype={\"store_and_fwd_flag\": \"string\"},\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# Prefetch first chunk\n",
    "first_chunk = next(df_iter)\n",
    "print(\"Prefetched rows:\", len(first_chunk))\n",
    "\n",
    "# Create/replace table schema (empty table with correct columns)\n",
    "first_chunk.head(0).to_sql(\"yellow_taxi_data\", con=engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Prepare COPY statement (quote column names safely)\n",
    "cols = list(first_chunk.columns)\n",
    "cols_sql = \", \".join([f'\"{c}\"' for c in cols])\n",
    "copy_sql = f'COPY yellow_taxi_data ({cols_sql}) FROM STDIN WITH (FORMAT csv, HEADER false)'\n",
    "\n",
    "def copy_chunk(conn, chunk: pd.DataFrame):\n",
    "    # ensure same column order\n",
    "    chunk = chunk[cols]\n",
    "\n",
    "    # write chunk to in-memory CSV\n",
    "    buf = StringIO()\n",
    "    chunk.to_csv(buf, index=False, header=False)\n",
    "    buf.seek(0)\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.copy_expert(copy_sql, buf)\n",
    "    conn.commit()\n",
    "\n",
    "# COPY first chunk\n",
    "copy_chunk(pg_conn, first_chunk)\n",
    "print(\"Copied chunk 1\")\n",
    "\n",
    "# COPY the rest with tqdm\n",
    "for i, chunk in enumerate(tqdm(df_iter), start=2):\n",
    "    copy_chunk(pg_conn, chunk)\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Copied chunk {i}\", flush=True)\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7062b78-857f-43b3-9aac-7004009b07e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n\n",
       "0  1250000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_sql(\"SELECT COUNT(*) AS n FROM yellow_taxi_data\", con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ce056e-e642-4c29-959f-edbe9f5a244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows already loaded: 1250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidTextRepresentation",
     "evalue": "invalid input syntax for type bigint: \"2.0\"\nCONTEXT:  COPY yellow_taxi_data, line 1, column VendorID: \"2.0\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidTextRepresentation\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# continue COPY\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(df_iter), start=\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43mcopy_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpg_conn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     22\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResumed: copied \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m more chunks\u001b[39m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mcopy_chunk\u001b[39m\u001b[34m(conn, chunk)\u001b[39m\n\u001b[32m     35\u001b[39m buf.seek(\u001b[32m0\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m conn.cursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy_expert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy_sql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m conn.commit()\n",
      "\u001b[31mInvalidTextRepresentation\u001b[39m: invalid input syntax for type bigint: \"2.0\"\nCONTEXT:  COPY yellow_taxi_data, line 1, column VendorID: \"2.0\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "n_loaded = int(pd.read_sql(\"SELECT COUNT(*) AS n FROM yellow_taxi_data\", con=engine).iloc[0,0])\n",
    "print(\"Rows already loaded:\", n_loaded)\n",
    "\n",
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=50_000,\n",
    "    dtype={\"store_and_fwd_flag\": \"string\"},\n",
    "    low_memory=False,\n",
    "    skiprows=range(1, n_loaded + 1),  # skip header handled by range starting at 1\n",
    ")\n",
    "\n",
    "# continue COPY\n",
    "for i, chunk in enumerate(tqdm(df_iter), start=1):\n",
    "    copy_chunk(pg_conn, chunk)\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Resumed: copied {i} more chunks\", flush=True)\n",
    "\n",
    "print(\"Resume done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "375f0e7d-0305-495c-8177-6615b15d94f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolled back\n"
     ]
    }
   ],
   "source": [
    "pg_conn.rollback()\n",
    "print(\"Rolled back\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8644b2a2-5d3f-4a9a-8964-fca119bc8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_conn.rollback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be13c31d-7cbc-431a-b302-988f50da09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "INT_LIKE_COLS = [\"VendorID\", \"RatecodeID\", \"passenger_count\", \"payment_type\"]\n",
    "\n",
    "def normalize_types(chunk: pd.DataFrame) -> pd.DataFrame:\n",
    "    chunk = chunk.copy()\n",
    "    for c in INT_LIKE_COLS:\n",
    "        if c in chunk.columns:\n",
    "            chunk[c] = pd.to_numeric(chunk[c], errors=\"coerce\").astype(\"Int64\")\n",
    "    return chunk\n",
    "\n",
    "def copy_chunk(conn, chunk: pd.DataFrame):\n",
    "    chunk = chunk[cols]\n",
    "    chunk = normalize_types(chunk)\n",
    "\n",
    "    buf = StringIO()\n",
    "    chunk.to_csv(buf, index=False, header=False, na_rep=\"\")\n",
    "    buf.seek(0)\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.copy_expert(copy_sql, buf)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75a2837-e597-4c7b-9b25-1ea5f06e8b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows already loaded: 1250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "csv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "n_loaded = int(pd.read_sql(\"SELECT COUNT(*) AS n FROM yellow_taxi_data\", con=engine).iloc[0,0])\n",
    "print(\"Rows already loaded:\", n_loaded)\n",
    "\n",
    "df_iter = pd.read_csv(\n",
    "    csv_url,\n",
    "    iterator=True,\n",
    "    chunksize=50_000,\n",
    "    dtype={\"store_and_fwd_flag\": \"string\"},\n",
    "    low_memory=False,\n",
    "    skiprows=range(1, n_loaded + 1),\n",
    ")\n",
    "\n",
    "for i, chunk in enumerate(tqdm(df_iter), start=1):\n",
    "    copy_chunk(pg_conn, chunk)\n",
    "\n",
    "print(\"Resume done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56297c2f-92cc-4e14-a6f6-7e05743bda34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1369765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n\n",
       "0  1369765"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"SELECT COUNT(*) AS n FROM yellow_taxi_data\", con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70a6b6f-f0fe-400e-9d0d-af24190f4e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2021-01-01 00:30:10   2021-01-01 00:36:12                1   \n",
       "1         1  2021-01-01 00:51:20   2021-01-01 00:52:19                1   \n",
       "2         1  2021-01-01 00:43:30   2021-01-01 01:11:06                1   \n",
       "3         1  2021-01-01 00:15:48   2021-01-01 00:31:01                0   \n",
       "4         2  2021-01-01 00:31:49   2021-01-01 00:48:21                1   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           2.10           1                  N           142            43   \n",
       "1           0.20           1                  N           238           151   \n",
       "2          14.70           1                  N           132           165   \n",
       "3          10.60           1                  N           138           132   \n",
       "4           4.94           1                  N            68            33   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          8.0    3.0      0.5        0.00           0.0   \n",
       "1             2          3.0    0.5      0.5        0.00           0.0   \n",
       "2             1         42.0    0.5      0.5        8.65           0.0   \n",
       "3             1         29.0    0.5      0.5        6.05           0.0   \n",
       "4             1         16.5    0.5      0.5        4.06           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3         11.80                   2.5  \n",
       "1                    0.3          4.30                   0.0  \n",
       "2                    0.3         51.95                   0.0  \n",
       "3                    0.3         36.35                   0.0  \n",
       "4                    0.3         24.36                   2.5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"SELECT * FROM yellow_taxi_data LIMIT 5\", con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2af6c63-08ca-43d2-aad7-99ebcd06b2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_pickup</th>\n",
       "      <th>max_pickup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-31 23:05:14</td>\n",
       "      <td>2021-02-22 16:52:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            min_pickup           max_pickup\n",
       "0  2008-12-31 23:05:14  2021-02-22 16:52:16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "  MIN(tpep_pickup_datetime) AS min_pickup,\n",
    "  MAX(tpep_pickup_datetime) AS max_pickup\n",
    "FROM yellow_taxi_data\n",
    "\"\"\", con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337a657b-de48-427c-bdd1-1ab0acb1f18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_rows</th>\n",
       "      <th>progress_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   table_rows  progress_rows\n",
       "0           0              0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# --- Recreate engine ---\n",
    "PG_HOST = os.environ.get(\"POSTGRES_HOST\", \"ny_taxi_pg\")\n",
    "PG_PORT = int(os.environ.get(\"POSTGRES_PORT\", \"5432\"))\n",
    "PG_USER = os.environ[\"POSTGRES_USER\"]\n",
    "PG_PASS = os.environ[\"POSTGRES_PASSWORD\"]\n",
    "PG_DB   = os.environ[\"POSTGRES_DB\"]\n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\")\n",
    "\n",
    "TABLE_NAME = \"yellow_taxi_data\"\n",
    "LOAD_ID = \"yellow_2021_01\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # 1) Ensure progress table exists (so DELETE won't fail)\n",
    "    conn.execute(text(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS etl_load_progress (\n",
    "        load_id TEXT PRIMARY KEY,\n",
    "        table_name TEXT NOT NULL,\n",
    "        source_url TEXT NOT NULL,\n",
    "        chunk_size INT NOT NULL,\n",
    "        rows_loaded BIGINT NOT NULL DEFAULT 0,\n",
    "        chunks_loaded BIGINT NOT NULL DEFAULT 0,\n",
    "        last_success_at TIMESTAMPTZ,\n",
    "        last_error_at TIMESTAMPTZ,\n",
    "        last_error TEXT\n",
    "    );\n",
    "    \"\"\"))\n",
    "\n",
    "    # 2) Truncate data table if it exists (skip if not yet created)\n",
    "    conn.execute(text(f'DO $$ BEGIN '\n",
    "                      f'IF to_regclass(\\'public.\"{TABLE_NAME}\"\\') IS NOT NULL THEN '\n",
    "                      f'EXECUTE \\'TRUNCATE TABLE \"{TABLE_NAME}\"\\'; '\n",
    "                      f'END IF; '\n",
    "                      f'END $$;'))\n",
    "\n",
    "    # 3) Reset progress for this load id\n",
    "    conn.execute(text(\"DELETE FROM etl_load_progress WHERE load_id = :load_id\"), {\"load_id\": LOAD_ID})\n",
    "\n",
    "# Sanity check\n",
    "pd.read_sql(f\"\"\"\n",
    "SELECT\n",
    "  COALESCE((SELECT COUNT(*) FROM \"{TABLE_NAME}\"), 0) AS table_rows,\n",
    "  (SELECT COUNT(*) FROM etl_load_progress WHERE load_id = '{LOAD_ID}') AS progress_rows\n",
    "\"\"\", con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c484d920-1538-4600-a50f-187a3556a974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[progress] rows_loaded=0 chunks_loaded=0\n",
      "[ok] copied chunk 1 total_rows=50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:18,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[complete] rows_loaded=1369765 chunks_loaded=28\n",
      "         n\n",
      "0  1369765\n",
      "          load_id        table_name  \\\n",
      "0  yellow_2021_01  yellow_taxi_data   \n",
      "\n",
      "                                          source_url  chunk_size  rows_loaded  \\\n",
      "0  https://github.com/DataTalksClub/nyc-tlc-data/...       50000      1369765   \n",
      "\n",
      "   chunks_loaded                  last_success_at last_error_at last_error  \n",
      "0             28 2026-02-04 14:36:53.951439+00:00          None       None  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "CSV_URL = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "TABLE_NAME = \"yellow_taxi_data\"\n",
    "LOAD_ID = \"yellow_2021_01\"          # change if you load a different file\n",
    "CHUNK_SIZE = 50_000\n",
    "INT_LIKE_COLS = [\"VendorID\", \"RatecodeID\", \"passenger_count\", \"payment_type\"]\n",
    "\n",
    "# Read DB creds from environment (docker-compose env_file injects these)\n",
    "PG_HOST = os.environ.get(\"POSTGRES_HOST\", \"ny_taxi_pg\")\n",
    "PG_PORT = int(os.environ.get(\"POSTGRES_PORT\", \"5432\"))\n",
    "PG_USER = os.environ[\"POSTGRES_USER\"]\n",
    "PG_PASS = os.environ[\"POSTGRES_PASSWORD\"]\n",
    "PG_DB   = os.environ[\"POSTGRES_DB\"]\n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\")\n",
    "pg_conn = psycopg2.connect(host=PG_HOST, port=PG_PORT, user=PG_USER, password=PG_PASS, dbname=PG_DB)\n",
    "pg_conn.autocommit = False\n",
    "\n",
    "# ----------------------------\n",
    "# HELPERS\n",
    "# ----------------------------\n",
    "def ensure_progress_table():\n",
    "    ddl = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS etl_load_progress (\n",
    "        load_id TEXT PRIMARY KEY,\n",
    "        table_name TEXT NOT NULL,\n",
    "        source_url TEXT NOT NULL,\n",
    "        chunk_size INT NOT NULL,\n",
    "        rows_loaded BIGINT NOT NULL DEFAULT 0,\n",
    "        chunks_loaded BIGINT NOT NULL DEFAULT 0,\n",
    "        last_success_at TIMESTAMPTZ,\n",
    "        last_error_at TIMESTAMPTZ,\n",
    "        last_error TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(ddl))\n",
    "\n",
    "def get_progress():\n",
    "    q = text(\"SELECT rows_loaded, chunks_loaded FROM etl_load_progress WHERE load_id = :load_id\")\n",
    "    with engine.begin() as conn:\n",
    "        row = conn.execute(q, {\"load_id\": LOAD_ID}).fetchone()\n",
    "    if row is None:\n",
    "        return 0, 0\n",
    "    return int(row[0]), int(row[1])\n",
    "\n",
    "def upsert_progress(rows_loaded: int, chunks_loaded: int, error: str | None = None):\n",
    "    sql = text(\"\"\"\n",
    "    INSERT INTO etl_load_progress(load_id, table_name, source_url, chunk_size, rows_loaded, chunks_loaded, last_success_at, last_error_at, last_error)\n",
    "    VALUES (:load_id, :table_name, :source_url, :chunk_size, :rows_loaded, :chunks_loaded,\n",
    "            CASE WHEN :error IS NULL THEN NOW() ELSE NULL END,\n",
    "            CASE WHEN :error IS NOT NULL THEN NOW() ELSE NULL END,\n",
    "            :error)\n",
    "    ON CONFLICT (load_id) DO UPDATE SET\n",
    "        table_name = EXCLUDED.table_name,\n",
    "        source_url = EXCLUDED.source_url,\n",
    "        chunk_size = EXCLUDED.chunk_size,\n",
    "        rows_loaded = EXCLUDED.rows_loaded,\n",
    "        chunks_loaded = EXCLUDED.chunks_loaded,\n",
    "        last_success_at = CASE WHEN EXCLUDED.last_error IS NULL THEN NOW() ELSE etl_load_progress.last_success_at END,\n",
    "        last_error_at   = CASE WHEN EXCLUDED.last_error IS NOT NULL THEN NOW() ELSE etl_load_progress.last_error_at END,\n",
    "        last_error      = EXCLUDED.last_error;\n",
    "    \"\"\")\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(sql, {\n",
    "            \"load_id\": LOAD_ID,\n",
    "            \"table_name\": TABLE_NAME,\n",
    "            \"source_url\": CSV_URL,\n",
    "            \"chunk_size\": CHUNK_SIZE,\n",
    "            \"rows_loaded\": rows_loaded,\n",
    "            \"chunks_loaded\": chunks_loaded,\n",
    "            \"error\": error\n",
    "        })\n",
    "\n",
    "def normalize_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in INT_LIKE_COLS:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def make_copy_sql(cols):\n",
    "    cols_sql = \", \".join([f'\"{c}\"' for c in cols])\n",
    "    return f'COPY {TABLE_NAME} ({cols_sql}) FROM STDIN WITH (FORMAT csv, HEADER false)'\n",
    "\n",
    "def copy_chunk(conn, copy_sql: str, cols: list[str], df: pd.DataFrame):\n",
    "    df = df[cols]\n",
    "    df = normalize_types(df)\n",
    "\n",
    "    buf = StringIO()\n",
    "    df.to_csv(buf, index=False, header=False, na_rep=\"\")\n",
    "    buf.seek(0)\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.copy_expert(copy_sql, buf)\n",
    "\n",
    "# ----------------------------\n",
    "# MAIN LOAD (resume-safe)\n",
    "# ----------------------------\n",
    "ensure_progress_table()\n",
    "\n",
    "rows_loaded, chunks_loaded = get_progress()\n",
    "print(f\"[progress] rows_loaded={rows_loaded} chunks_loaded={chunks_loaded}\")\n",
    "\n",
    "# (Re)create the iterator, skipping already loaded rows\n",
    "df_iter = pd.read_csv(\n",
    "    CSV_URL,\n",
    "    iterator=True,\n",
    "    chunksize=CHUNK_SIZE,\n",
    "    dtype={\"store_and_fwd_flag\": \"string\"},\n",
    "    low_memory=False,\n",
    "    skiprows=range(1, rows_loaded + 1)  # skip data rows; keep header\n",
    ")\n",
    "\n",
    "# If we're starting fresh, we need to create the table schema\n",
    "# If resuming, we must not replace the table.\n",
    "try:\n",
    "    if rows_loaded == 0:\n",
    "        first = next(df_iter)\n",
    "        cols = list(first.columns)\n",
    "\n",
    "        # Create empty table schema\n",
    "        first.head(0).to_sql(TABLE_NAME, con=engine, if_exists=\"replace\", index=False)\n",
    "        copy_sql = make_copy_sql(cols)\n",
    "\n",
    "        # Copy first chunk\n",
    "        copy_chunk(pg_conn, copy_sql, cols, first)\n",
    "        pg_conn.commit()\n",
    "\n",
    "        rows_loaded += len(first)\n",
    "        chunks_loaded += 1\n",
    "        upsert_progress(rows_loaded, chunks_loaded, error=None)\n",
    "        print(f\"[ok] copied chunk {chunks_loaded} total_rows={rows_loaded}\")\n",
    "    else:\n",
    "        # Get column order from the existing table (important!)\n",
    "        with engine.begin() as conn:\n",
    "            cols = [r[0] for r in conn.execute(text(f\"\"\"\n",
    "                SELECT column_name\n",
    "                FROM information_schema.columns\n",
    "                WHERE table_name = :t\n",
    "                ORDER BY ordinal_position\n",
    "            \"\"\"), {\"t\": TABLE_NAME}).fetchall()]\n",
    "        copy_sql = make_copy_sql(cols)\n",
    "\n",
    "    # Continue streaming remaining chunks\n",
    "    for df_chunk in tqdm(df_iter):\n",
    "        copy_chunk(pg_conn, copy_sql, cols, df_chunk)\n",
    "        pg_conn.commit()\n",
    "\n",
    "        rows_loaded += len(df_chunk)\n",
    "        chunks_loaded += 1\n",
    "        upsert_progress(rows_loaded, chunks_loaded, error=None)\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"[done] no data (iterator empty)\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Roll back DB transaction so the connection can be reused after restart\n",
    "    try:\n",
    "        pg_conn.rollback()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Persist the failure info for next run\n",
    "    upsert_progress(rows_loaded, chunks_loaded, error=str(e))\n",
    "\n",
    "    print(\"\\n[FAILED]\")\n",
    "    print(\"Saved progress so you can rerun this cell to resume.\")\n",
    "    print(\"rows_loaded =\", rows_loaded)\n",
    "    print(\"chunks_loaded =\", chunks_loaded)\n",
    "    print(\"error =\", repr(e))\n",
    "    raise\n",
    "\n",
    "finally:\n",
    "    # Keep connections open if you want; otherwise close them\n",
    "    # pg_conn.close()\n",
    "    pass\n",
    "\n",
    "print(f\"\\n[complete] rows_loaded={rows_loaded} chunks_loaded={chunks_loaded}\")\n",
    "print(pd.read_sql(f\"SELECT COUNT(*) AS n FROM {TABLE_NAME}\", con=engine))\n",
    "print(pd.read_sql(\"SELECT * FROM etl_load_progress WHERE load_id = %s\" % repr(LOAD_ID), con=engine))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41386d44-ef3f-4a4a-95c0-e73bee461021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
